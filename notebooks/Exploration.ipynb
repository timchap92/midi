{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pretty_midi\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm_notebook\n",
    "import pickle\n",
    "import shutil\n",
    "import ast\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Masking, Embedding\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv('data/maestro-v2.0.0/maestro-v2.0.0.csv')\n",
    "\n",
    "len(metadata)\n",
    "\n",
    "%timeit pretty_midi.PrettyMIDI(os.path.join('data/maestro-v2.0.0', row['midi_filename']))\n",
    "\n",
    "songs = []\n",
    "for _, row in tqdm_notebook(list(metadata.iterrows())):\n",
    "    midi = pretty_midi.PrettyMIDI(os.path.join('data/maestro-v2.0.0', row['midi_filename']))\n",
    "    midi.split = row['split']\n",
    "    songs.append(midi)\n",
    "\n",
    "shutil.rmtree('data/songs.txt', ignore_errors=True)\n",
    "for midi in tqdm_notebook(songs):\n",
    "    assert len(midi.instruments) == 1\n",
    "    with open('data/songs.txt', 'a') as f:\n",
    "        f.write('{split}#{tempo}#{notes}\\n'.format(\n",
    "            split=midi.split, tempo=midi.estimate_tempo(), \n",
    "            notes=[(n.start, n.end, n.pitch, n.velocity) for n in midi.instruments[0].notes]\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create labelled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Note:\n",
    "    \n",
    "    def __init__(self, start, end, pitch, velocity):\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "        self.pitch = pitch\n",
    "        self.velocity = velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_string(s):\n",
    "    split, tempo, notes = s.split('#')\n",
    "    tempo = float(tempo)\n",
    "    notes = [Note(*tpl) for tpl in ast.literal_eval(notes)]\n",
    "    return split, tempo, notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(notes, nb_timesteps):\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    for i in range(nb_timesteps, len(notes)):\n",
    "        sequences.append(np.array([n.pitch for n in notes[i - nb_timesteps:i]]))\n",
    "        labels.append(notes[i].pitch)\n",
    "    return sequences, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_lines = 0\n",
    "with open('data/songs.txt') as f:\n",
    "    for line in f:\n",
    "        nb_lines += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86b20a5d4bf54767b6b4dfbe57b67cb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1341), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "count_by_pitch = np.zeros(shape=128)\n",
    "with open('data/songs.txt') as f:\n",
    "    for line in tqdm_notebook(f, total=nb_lines):\n",
    "        split, tempo, notes = process_string(line)\n",
    "        for note in notes:\n",
    "            count_by_pitch[note.pitch] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fc945acdbe0>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(*zip(*list(enumerate(count_by_pitch))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constrain_pitch(pitch, min_pitch, max_pitch):\n",
    "    if pitch < min_pitch:\n",
    "        pitch = pitch % 12 + 12 * (min_pitch // 12) + 12\n",
    "        if pitch >= min_pitch + 12:\n",
    "            pitch -= 12\n",
    "        assert min_pitch <= pitch < min_pitch + 12\n",
    "        return pitch\n",
    "    if pitch > max_pitch:\n",
    "        pitch = pitch % 12 + 12 * (max_pitch // 12) - 12\n",
    "        if pitch <= max_pitch - 12:\n",
    "            pitch += 12\n",
    "        assert max_pitch - 12 < pitch <= max_pitch\n",
    "        return pitch\n",
    "    return pitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "x_validate = []\n",
    "y_validate = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_pitch = 40\n",
    "max_pitch = 80\n",
    "nb_pitches = max_pitch - min_pitch + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_fraction = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "24GB with pitch 40-80, timesteps=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d2ca968716b48a39c83f080acc75f66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1341), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "random.seed(0)\n",
    "with open('data/songs.txt') as f:\n",
    "    for line in tqdm_notebook(f, total=nb_lines):\n",
    "        split, tempo, notes = process_string(line)\n",
    "        for note in notes:\n",
    "            note.pitch = constrain_pitch(note.pitch, min_pitch, max_pitch) - min_pitch\n",
    "        sequences, labels = create_features(notes, nb_timesteps=timesteps)\n",
    "        if split == 'train':\n",
    "            x_train.extend(sequences)\n",
    "            y_train.extend(labels)\n",
    "        elif split == 'validation':\n",
    "            x_validate.extend(sequences)\n",
    "            y_validate.extend(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = to_categorical(np.array(x_train), num_classes=nb_pitches)\n",
    "y_train = to_categorical(np.array(y_train), num_classes=nb_pitches)\n",
    "x_validate = to_categorical(np.array(x_validate), num_classes=nb_pitches)\n",
    "y_validate = to_categorical(np.array(y_validate), num_classes=nb_pitches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Recurrent layer\n",
    "model.add(LSTM(64, input_shape=(timesteps, nb_pitches),\n",
    "               return_sequences=False, dropout=0.1, recurrent_dropout=0.1))\n",
    "\n",
    "# Fully connected layer\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "# Dropout for regularization\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(nb_pitches, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create callbacks\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=5),\n",
    "             ModelCheckpoint('models/model.h5', save_best_only=True, save_weights_only=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5975834, 20, 41)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5975834, 41)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(657246, 20, 41)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_validate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(657246, 41)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_validate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0629 15:47:10.039770 140133684045568 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5975834 samples, validate on 657246 samples\n",
      "Epoch 1/150\n",
      " 559104/5975834 [=>............................] - ETA: 17:19 - loss: 3.4375 - accuracy: 0.0810"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-79d15bdbba42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2048\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                     validation_data=(x_validate, y_validate))\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3508\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3509\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3510\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3512\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    570\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m    571\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m--> 572\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;31m# Only need to override the gradient in graph mode and when we have outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_register_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args)\u001b[0m\n\u001b[1;32m    443\u001b[0m             attrs=(\"executor_type\", executor_type,\n\u001b[1;32m    444\u001b[0m                    \"config_proto\", config),\n\u001b[0;32m--> 445\u001b[0;31m             ctx=ctx)\n\u001b[0m\u001b[1;32m    446\u001b[0m       \u001b[0;31m# Replace empty list with None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train,  y_train, \n",
    "                    batch_size=2048, epochs=150,\n",
    "                    callbacks=callbacks,\n",
    "                    validation_data=(x_validate, y_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
